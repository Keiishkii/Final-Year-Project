\documentclass[11pt, a4paper]{article}

\usepackage[a4paper, width = 150 mm, top = 25 mm, bottom = 25 mm]{geometry}
\usepackage{amsfonts}
\usepackage{titlesec}
\usepackage{color}
\usepackage[backend=biber, citestyle=authoryear, sorting=nyt]{biblatex}\addbibresource{references.bib}


\title{Controlling Player Avatars in Game Worlds using Multi-Modal Input Systems}
\author{Charlie Lloyd-Buckingham}
\date{\today}

\newcommand{\citationneeded}{	\textcolor{red}{[Citation Need]}}
\newcommand{\citethis}[1]{(\cite{#1})}

\begin{document}

% Controlling Player Avatars in Game Worlds using Multi-Modal Input Systems
\maketitle



\pagebreak
\section{Acknowledgements}	
This is my acknowledgements.

\section{Abstract}	
My project is about....



\pagebreak
\tableofcontents				% - 300 Words



% Introducition and Context, Including Aim's and Objectives
\pagebreak
\section{Introduction}	
\subsection{Context}
Throughout the history of the games industry, game makers have been exploring new ways to deliver their players new experiences. This has come in the forms of narrative decisions within a games story, stylistic decisions through the games art and, as a focus for this paper, the interaction systems designed around the players influence within the games world. 

\hfill

On account of the digital nature of video games, as technology has evolved over the years so too has the hardware and interaction methodologies used within gaming consoles. Beginning in 1972 with the creation of the first home console, the Magnavox Odyssey, over the following years, video game console manufactures have continued to push the perceived boundaries of interactive entertainment. In 2006, Nintendo demonstrated to the world the potential of a motion controlled input system with the Wii. Following this, other manufactures also began to expand into the technology, with Microsoft developing the Xbox Kinect and Sony the PlayStation Move. Nowadays, companies like Oculus and the HTC corporation are exploring the market of consumer virtual reality headsets with the Quest and Vive, while Nintendo is showing off new ways of using old technology with their Labo Toycon games. All of this has demonstrated that with the markets continued interest in new experiences, console manufactures and game developers will continue innovating new methods of interaction to for their players.

\subsection{Research Problem}
Specifically of note, there has also been a growing interest in the usage of electroencephalographic (EEG) and electromyographic (EMG) techniques being coupled with game engines for purposes of research. The use of games in biological and psychological research has been present for many years, due to the benefits gained from controlling how a subject interacts and is stimulated throughout a experiments lifetime. The act of reversing this dynamic and using these systems for the purposes of interacting with video games with the lens of entertainment has also been explored \citethis{6518141}, however we are still yet to see anything come out of this for the general consumer population. 

\subsection{Project Aims}
It is with this in mind, that this paper proposes to continue with this exploration into the usage of EEG, EMG, and other additional input modalities for video games. By acquiring data from all devices and combining them, the hope is that with the right method for analysis, a single system will be able to attain and extract meaningful interactions from its users to be used with a game world. The creation of such a system will be the aim of the paper, along side this, two games will also be constructed, these will be used to demonstrate and verify that the system is capable of performing its tasks correctly from within a potential use-case environment.

\subsection{Project Objectives}
To get this system working, data from each device will need to be accessed live and streamed into the Unity game engine where a pre-trained artificial neural network (ANN) will be used to decipher a meaning suitable for the given game. From this the two games will be developed: the first, a simple avatar controller, where the player will use motor imagery to control the limbs of a virtual avatar; the second game will use the system to allow for adaptive difficulty based on the users state of mind, making tasks harder to perform based on how unfocused the system interprets the user to be.



% Review of Literature and / or Proffesional Practices
\pagebreak
\section{Research}	
\subsection{Literature Review}	% - 2000 Words
The existence of multi-modal input system is not unheard of, almost all modern first person console shooters use the input controllers built in gyroscope in addition to the right joystick to control the direction of the players camera, this multi-input system allows much more finesse when aiming, resulting in the players having a more enjoyable experience \citethis{toktacs2019evaluation}. In the work put forward by Gon \citethis{da2014multimodal}, he demonstrates that the inclusion of a multi-modal input system when compared to a uni-modal input system can make video games perceivably more enjoyable, "it can be used to increase the feeling of empowerment on the player when using certain abilities, or to intentionally make in-game actions more difficult by demanding more physical effort from the player". Though gyroscopic-assisted aiming is a more recent phenomenon, the solution of combining multiple inputs for a singular interaction within a game has been around for a while. Even back in 2009 with the release of 'The Legend of Zelda: Spirit Tracks' \citethis{thelegendofzelda_spirittracks}, multi-input controls where used. In which, to play specific tones on the games flute item, the player would be required to blow into the microphone and using the touch screen to move the flutes pipes into the center of the screen to select the tone. This interaction could very easily be performed using just the touch screen or even the Nintendo DS's buttons, much like how previous musical instruments in the franchise where implemented - Majoras Mask \citethis{thelegendofzelda_majorasmask}. However, as stated by Gon, players will have felt a "feeling of empowerment" overcoming the set-pieces Nintendo designed, rather then just going through the motions of pressing the right buttons.

\hfill

Before looking into EEG as a single piece of a larger multi-modal input system, we can look into how it can be used on its own with video games. The main usage of EEG based gaming is serous games, defined by Alvarez as a video game that is "intended to depart from the simple entertainment" \citethis{alvarez2011introduction}. This refers to the games built research, education and rehabilitation, whether this is just for providing an environment for the comparison between different electroencephalographs \citethis{liarokapis2014comparing}, evaluating a participants emotions and satisfaction \citethis{vourvopoulos2013brain}, screening for early signs of mental illness \citethis{tarnanas2015comparison}, or cognitive rehabilitation \citethis{alchalcabi2017more}. When using EEG, the data captured from the device can be interpreted in a multitude of different ways, depending on what is required. Games can be used to invoke the necessary mental state needed for event related potentials \citethis{ahn2011using}, or to provide real-time feed back when measuring changes in mental states \citethis{liarokapis2015examining} and motor-imagery \citethis{ndulue2019driving}. It is however debated whether EEG technology is still in its infancy. When analysing the current state of BCI usability Rashid \citethis{rashid2020current} writes "In spite of the many outstanding breakthroughs that have been achieved in BCI research, some issues still need to be resolved...  ...the existing BCIs offer somewhat poor ITR for any type of effectual BCI application", while Cattan when comparing information transfer speed writes ".In practice, this means that BCIs are unusable in traditional inputs, such as in keyboards or mice". On the over hand however, the lengths at which EEG has been able to allow for in game interactions have been reasonably impressive: from modifying the games difficulty through the users measured focus in Tetris \citethis{liarokapis2015examining}; to using motor-imagery for walking around the streets of Ancient Rome in Rome Reborn, \citethis{ndulue2019driving} and piloting a space ship in Rock Evaders \citethis{ndulue2019driving}.

\hfill

The usage of EMG with video games has also been quite extensive. Serous gaming within EMG has allowed for the research various topics, measuring arousal to stimuli using facial muscles \citethis{schuurink2008engagement}, to the effectiveness of myoelectric prosthesis training \citethis{bessa2020designing}; while there use outside of research has helped in patient rehabilitation, post injury \citethis{gutierrez2020serious} \citethis{schonauer2011full}, strokes \citethis{ghassemi2019development} and other medical disorders \citethis{labruyere2013requirements}. Though with a much smaller scope, entertainment focused EMG video games do exist. In large part to allow for motor impaired people to be given the option to play games, Kamau-Mugro states "focusing on neck EMG, would give more control to individuals with hand disabilities or SCI patient as a control scheme or an entertainment interface" \citethis{muguro2020development}.

\hfill

Having demonstrated that EEG and EMG can be used as uni-modal input systems, we can now explore their usage when combined with additional input modalities. Though the usage as a direct input for entertainment based gaming is lacklustre, serous games and EEG have been used for multi-modal analysis, using data from in-game events coupled with the EEG input streams \citethis{sivanathan2014temporal}. This isn't to say however that inspiration for video game input system can't come from something else, there is a large portion of research in which multi-modal EEG and EMG systems have been used in the development for consumer prosthetics \citethis{shi2019novel} and wheelchair controllers \citethis{carlson2013brain}. These systems build upon the context for the data EEG and EMG provide, through the use of eye-tracking, computer vision and inverse kinematics \citethis{mcmullen2013demonstration}. With which expanding these systems from would otherwise be a somewhat inaccurate, cumbersome and slow, to real time viable real world solutions. 



\pagebreak
\section{Methodology and Process}			% - 3100 Words





\pagebreak
\section{Conclusion and Future Work}

\subsection{Conclusion}

\subsection{Future Work}			% - 300 Words



		% - 300 Words

\pagebreak
\printbibliography
\printbibliography[keyword = software, title = {Software}]

\end{document}