\documentclass[11pt, a4paper]{article}

\usepackage[a4paper, width = 150 mm, top = 25 mm, bottom = 25 mm]{geometry}
\usepackage{amsfonts}
\usepackage{titlesec}
\usepackage{color}
\usepackage[backend=biber, citestyle=authoryear, sorting=nyt]{biblatex}\addbibresource{references.bib}


\title{Controlling Player Avatars in Game Worlds using Multi-Modal Input Systems}
\author{Charlie Lloyd-Buckingham}
\date{\today}

\newcommand{\citationneeded}{	\textcolor{red}{[Citation Need]}}
\newcommand{\citethis}[1]{(\cite{#1})}

\begin{document}

% Controlling Player Avatars in Game Worlds using Multi-Modal Input Systems
\maketitle



\pagebreak
\section{Acknowledgements}	
This is my acknowledgements.

\section{Abstract}	
My project is about....



\pagebreak
\tableofcontents				% - 300 Words



% Introducition and Context, Including Aim's and Objectives
\pagebreak
\section{Introduction}	
\subsection{Context}
Throughout the history of the games industry, game makers have been exploring new ways to deliver their players new experiences. This has come in the forms of narrative decisions within a games story, stylistic decisions through the games art and, as a focus for this paper, the interaction systems designed around the players influence within a games world. 

\hfill

On account of the digital nature of video games, as technology has evolved over the years so too has the hardware and methods of interaction used within gaming consoles. Beginning in 1972 with the creation of the first home console, the Magnavox Odyssey, over the following years, video game console manufactures have continued to push the perceived boundaries of interactive entertainment. In 2006, Nintendo demonstrated to the world the potential of a motion controlled input system with the Wii. Following this, other manufactures also began to expand into the technology, with Microsoft developing the Xbox Kinect and Sony the PlayStation Move. Nowadays, companies like Oculus and the HTC corporation are exploring the market of consumer virtual reality headsets with the Quest and Vive, while Nintendo is showing off new ways of using old technology with their Labo Toycon games. All of this has demonstrated that with the markets continued interest in new experiences, console manufactures and game developers will continue innovating new methods of interaction for their players.

\subsection{Research Problem}
There has also been a growing interest in the usage of electroencephalographic (EEG) and electromyographic (EMG) techniques being coupled with game engines for purposes of research. The use of games in biological and psychological research has been present for many years, due to the benefits gained from controlling how a subject is stimulated throughout an experiments lifetime. The act of reversing this dynamic and using these systems for the purposes of entertainment has also been explored \citethis{6518141}, however there is still yet be any substantial product, viable for consumers to play. 

\subsection{Project Aims}
It is with this in mind, that this paper proposes to continue with the investigation into the viability of EEG, EMG, and other additional input modalities within video games. By acquiring data from all devices and combining them, the aim is for a single system to be able to attain and extract meaningful interactions from its users to be used to control aspects of game world. The creation of such a system will be the aim of the paper. Along side this, two example games will also be constructed, these will be used to demonstrate and verify that the system is capable of performing its tasks correctly from within a potential use-case environment.

\subsection{Project Objectives}
To get this system working, data from each device will need to be accessed live and streamed into the Unity game engine where a pre-trained artificial neural network (ANN) will be used to decipher a meaning suitable for the given game. From this the two games will be developed: the first will have the player use motor imagery to control the limbs of a virtual avatar; the second game will use the system measure the users state of mind, allowing for adaptive difficulty depending on how focused the player is determined to be.



% Review of Literature and / or Proffesional Practices
\pagebreak
\section{Research}	
\subsection{Literature Review}	% - 2000 Words
The usage of multi-modal input systems is not unheard of, almost all modern first person console shooters use the input controllers built in gyroscope in addition to the right joystick to control the direction of the players camera, this multi-input system allows much more finesse when aiming, resulting in the players having a more enjoyable experience \citethis{toktacs2019evaluation}. In the work put forward by Gon \citethis{da2014multimodal}, he demonstrates that the inclusion of a multi-modal input system when compared to a uni-modal input system can make video games perceivably more enjoyable, "it can be used to increase the feeling of empowerment on the player when using certain abilities, or to intentionally make in-game actions more difficult by demanding more physical effort from the player". Though gyroscopic-assisted aiming is a more recent phenomenon, the concept of incorporating multiple input systems for singular interactions within gaming has been around for a while. Even back in 2009 with the release of 'The Legend of Zelda: Spirit Tracks' \citethis{thelegendofzelda_spirittracks}, the player when using the games flute item, would be required to blow into the 3DS microphone and use its touch screen to play specific tones. This interaction could have very easily be performed by mapping tones to regions on the touch screen, or pairing each tone to a button on the Nintendo 3DS, much like how previous instruments in the franchise have been implemented, E.g. 'The Legend of Zelda: Majoras Mask' \citethis{thelegendofzelda_majorasmask}. However, as stated by Gon, players could feel a "feeling of empowerment" overcoming the set-pieces Nintendo designed, through this added multi-modal challenge.

\hfill

Before looking into EEG as a part of a larger multi-modal input system, we can look into how it has been used on its own with video games. The main usage of EEG based gaming comes from serious games, defined by Alvarez \citethis{alvarez2011introduction} as a video game that is "intended to depart from the simple entertainment". This refers to games built for research, education and rehabilitation. Whether this is just for providing an environment for the comparison between different electroencephalographs \citethis{liarokapis2014comparing}, evaluating a participants emotions and satisfaction \citethis{vourvopoulos2013brain}, screening for early signs of mental illness \citethis{tarnanas2015comparison}, or cognitive rehabilitation \citethis{alchalcabi2017more}. 

The data captured from EEG can be used in a multitude of ways, depending on what is considered important for a given experiment. By using games it is then possible to focus on these targeted aspects of EEG: allowing for the invocation of biological response necessary for event related potentials \citethis{ahn2011using}, or to provide a real-time environment capable of visually demonstration the measurements of changes in mental states \citethis{liarokapis2015examining} and motor-imagery \citethis{ndulue2019driving}. 

However, it is debated for whether EEG technology is still in its infancy. When investigating the current state of BCI usability, Rashid \citethis{rashid2020current} writes "In spite of the many outstanding breakthroughs that have been achieved in BCI research, some issues still need to be resolved...  ...the existing BCIs offer somewhat poor ITR for any type of effectual BCI application", while in Cattan \citethis{cattan2021use} comparison of BCI information transfer speed, he writes "In practice, this means that BCIs are unusable in traditional inputs, such as in keyboards or mice". To the contrary, the lengths at which EEG has already been used in video games as an interactive medium has been reasonably impressive: from modifying a games difficulty based on the focus of the player, in Tetris \citethis{liarokapis2015examining}; walking around the streets of Ancient Rome using motor-imagery, in Rome Reborn \citethis{ndulue2019driving}; too piloting a space ship in Rock Evaders \citethis{ndulue2019driving}. EEG has shown its potential as a possible use for video game control.

\hfill

The usage of EMG within video games has also been quite extensive. EMG based serious games have permitted the research of various topics, from measuring arousal to stimuli using the muscles in the face \citethis{schuurink2008engagement}, too the effectiveness of myoelectric prosthesis training \citethis{bessa2020designing}. While their use outside of research has aided in the rehabilitation of patients, suffering from: post injury \citethis{gutierrez2020serious} \citethis{schonauer2011full}; strokes \citethis{ghassemi2019development} and other medical disorders \citethis{labruyere2013requirements}. Though much more infrequent, entertainment focused EMG games do exist. In large part due to the goal of allowing motor impaired people to be given the option to play games, Kamau-Mugro states "focusing on neck EMG, would give more control to individuals with hand disabilities or SCI patient as a control scheme or an entertainment interface" \citethis{muguro2020development}.

\hfill
  
Having investigated the viability of EEG and EMG as uni-modal input systems, we can now explore their combined usage with additional input modalities. Though the appearance of entertainment based multi-modal EEG and EMG systems are lacklustre, multi-modal serious games using EEG and EMG are a lot more common. An example of which is Sivanathans work on multi-modal EEG analysis, in which data from in-game events was coupled with the EEG input streams to allow for more understanding of the data \citethis{sivanathan2014temporal}. This isn't to say that inspiration for a video game input system can't come from something else, the majority of research in which multi-modal EEG and EMG systems have been built for is in the development for consumer prosthetics \citethis{shi2019novel} and wheelchair controllers \citethis{carlson2013brain}. These systems pull from the data streams of EEG and EMG and by using eye-tracking, computer vision and inverse kinematics \citethis{mcmullen2013demonstration} are able to allow for finer control over hardware systems that on there own EEG and EMG wouldn't be able. By adopting a similar approach, these real world solutions can be used with virtual controllers instead. 


\pagebreak
\section{Methodology and Process}			% - 3100 Words

\begin{itemize}
  \item Setup of Unity enviroment for VR.
  \item LSL streams used for aquiring and writing data.
  \item Offline processing and spoofing "online data" (reading CSV files) and writing the data over the LSL network.
  \item I began by using python - (tensor flow, keras) - to classify EEG data using motor imagery to decide between a left and right motion.
\end{itemize}

\hfill




\pagebreak
\section{Conclusion and Future Work}

\subsection{Conclusion}

\subsection{Future Work}			% - 300 Words



		% - 300 Words

\pagebreak
\printbibliography
\printbibliography[keyword = {tree}]

\end{document}
